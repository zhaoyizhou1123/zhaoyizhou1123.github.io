<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Free from Bellman Completeness: Trajectory Stitching via Model-based Return-conditioned Supervised Learning">
  <!-- <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1"> -->
  <title>Accelerating Unbiased LLM Evaluation via Synthetic Feedback</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
  <!-- <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
  </script>
  <script type="text/javascript"
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <!-- <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://zhaoyizhou1123.github.io/">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>
    </div>

  </div> -->
</nav>



<!-- <section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">

    </div>
  </div>
</section> -->

<section class="section">
  <div class="container is-max-desktop">
    <!-- Title, Authors,links -->
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <h1 class="title is-1 publication-title">Accelerating Unbiased LLM Evaluation<br/>
          via Synthetic Feedback  <br/>
        </h1>
        <div class="is-size-5 publication-authors">
          <span class="author-block">
            <a href="https://zhaoyizhou1123.github.io/">Zhaoyi Zhou</a>,</span>
          <span class="author-block">
            <a href="https://yudasong.github.io/">Yuda Song</a>,</span>
          <span class="author-block">
            <a href="https://azanette.com/">Andrea Zanette</a>
          </span>
        </div>

        <div class="is-size-5 publication-authors">
          <span class="author-block">Carnegie Mellon University</span>
        </div>

        <div class="column has-text-centered">
          <div class="publication-links">
            <!-- arXiv Link. -->
            <span class="link-block">
              <a href="https://arxiv.org/abs/2502.10563"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="ai ai-arxiv"></i>
                </span>
                <span>arXiv</span>
              </a>
            </span>
            <!-- Video Link. -->
            <!-- <span class="link-block">
              <a href="https://youtu.be/6F8LmdUe65o"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="fab fa-youtube"></i>
                </span>
                <span>Video</span>
              </a>
            </span> -->
            <!-- Code Link. -->
            <span class="link-block">
              <a href="https://github.com/Zanette-Labs/control_variates_evaluation"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                    <i class="fab fa-github"></i>
                </span>
                <span>Code</span>
                </a>
            </span>
          </div>
        </div>
      </div>
    </div>
    <!-- / Title, Authors,links -->

    <!-- TLDR -->
    <div class="column has-text-centered">
      <p>
        <strong>TL;DR</strong> We propose Control Variates Evaluation, an unbiased LLM evaluation method with reduced human annotations.
      </p>
    </div>
    <!-- TLDR -->

  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width has-text-justified">
        <h2 class="title is-3 has-text-centered"> Motivation </h2>
        <div class="content has-text-justified">
          <p> 
            Accurately evaluating the performance of large language models (LLMs) is crucial before large-scale deployment. <em> Human evaluation </em> remains the gold standard, but this approach demands substantial time and financial resources. It may also diminish user experience when conducted with active system users,
          </p>
          <p>
            <em> Synthetic evaluation</em>, on the other hand, generates annotations using a reward model or LLM (e.g., GPT-4). Though reducing the need for extensive human involvement, synthetic evaluators can not perfectly reflect human preference and often introduce bias, undermining the evaluation reliability.
          </p>
          <p> In this work, we propose <em> Control Variates Evaluation </em> to integrate human and synthetic feedback, mitigating reliance on human annotations while maintaining unbiased evaluations. 
          </p>
        </div>
        <div class="content has-text-centered">
          <img src="./static/images/workflow_final.png" class="inline-figure" alt="workflow" 
          width="70%" height="auto"/>
          <!-- <img src="./static/images/bootstrap_err_v2.png" class="inline-figure" alt="mbrcsl" 
          width="40%" height="auto"/> -->
        </div>
        <p style="font-size: 0.8em; margin-top: 0.5rem">
          <strong>Figure 1:</strong> Control Variates Evaluation makes use of a possibly inaccurate synthetic evaluator to reduce the variance of evaluation, reducing the need of human annotations while preserving unbiasedness. 
        </p>
      </div>  
    </div>
  </div>
</section>

<!-- (Right) Averaged mean square error v.s. number of human annotations for Human Evaluation, Synthetic Evaluation and Control Variates Evaluation (ours) using the finetuned Skywork-8B evaluator on Chatbot Arena. The Synthetic Evaluation has high bias, while the bias of Human and Control Variates Evaluations are negligible. Control Variates Evaluation reduces the variance of Human Evaluation. -->

<!-- saving -->
<!-- <section class="section">
  <div class="container is-max-desktop">   
    <div class="columns is-centered">
      <div class="column is-full-width has-text-justified">
        <h2 class="title is-3 has-text-centered">Saving Human Annotations with Control Variates Evaluation </h2>
        <div class="content has-text-justified">
          <p>
            Control Variates Evaluation applies to a variety of benchmarks and synthetic evaluators, ranging from small 2B reward models to large language models. Our experiments (as shown in the table below) demonstrate a reduction in human annotations by up to 12.2% with an off-the-shelf synthetic evaluator and up to 24.8% with a finetuned variant. All these savings can be achieved with an easy-to-deploy reward model at nearly no cost.
          </p>
        </div>
        <div class="content has-text-centered">
          <img src="./static/images/saving_table.png" class="inline-figure" alt="saving table" 
          width="80%" height="auto"/>
        </div>
      </div>
    </div>
    
  </div>
</section> -->
<!-- / saving -->

<!-- predictable -->
<section class="section">
  <div class="container is-max-desktop">   
    <div class="columns is-centered">
      <div class="column is-full-width has-text-justified">
        <h2 class="title is-3 has-text-centered">Saving Is Predictable </h2>
        <div class="content has-text-justified">
          <p>
            Control variates theory indicates that the percentage of human annotation is predictable without actually running the evaluation process. This is demonstrated in the figure below, in which we shift the human evaluation curve according to theoretical prediction, and the shifted curve overlaps with the practical control variates evaluation curve.
          </p>
        </div>
        <div class="content has-text-centered">
          <img src="./static/images/bootstrap_all.png" class="inline-figure" alt="saving table" 
          width="50%" height="auto"/>
        </div>
        <p style="font-size: 0.8em; margin-top: 0.5rem">
          <strong>Figure 2:</strong> Averaged mean-square error versus number of human annotations for Skywork-8B (finetuned) on Chatbot Arena. The $x$-coordinate of curves "Human" and "Ours" correspond to the number of human annotations. The curve "Human (shifted)" is derived by horizontally scaling the Human Evaluation curve according to the theoretically predicated saving. The averaged mean-square error of Control Variates Evaluation (ours) converges to near 0, indicating that it has negligible bias in contrast with the high bias of synthetic evaluation. The human annotation saving ratio aligns perfectly with the actual variance relationship between Human Evaluation and Control Variates Evaluation.
        </p>
      </div>
    </div>
    
  </div>
</section>
<!--/ predictable -->

<!-- finetune -->
<section class="section">
  <div class="container is-max-desktop">   
    <div class="columns is-centered">
      <div class="column is-full-width has-text-justified">
        <h2 class="title is-3 has-text-centered">Finetuning Improves Saving </h2>
        <div class="content has-text-justified">
          <p>
            On many popular LLM evaluation benchmarks such as Chatbot Arena and MT Bench, there are abundant off-the-shelf human annotations for pre-generated language model responses. Now suppose we have a new LLM and we want to compare it with the existing ones in the benchmark. We can make use of these existing human annotations to finetune the synthetic evaluator before running the Control Variates Evaluation. 
          </p>
          <p>
            Note that the dataset used for finetuning the synthetic annotator contains responses generated by LLMs that are different from the LLMs that we wish to evaluate, i.e., the responses in evaluation dataset are out of distribution w.r.t. the finetuning data. Nevertheless, we show that the finetuned model still generalizes well in terms of the correlation coefficient to the human annotations, with a significant increase in human annotation saving.
          </p>
        </div>
        <div class="content has-text-centered">
          <img src="./static/images/chatbot-arena_pretrain_finetune_v3.png" class="inline-figure" alt="chatbot arena finetune" 
          width="30%" height="auto"/>
          <img src="./static/images/mt-bench_pretrain_finetune_v3.png" class="inline-figure" alt="mt bench finetune" 
          width="30%" height="auto"/>
        </div>
        <p style="font-size: 0.8em; margin-top: 0.5rem">
          <strong>Figure 3:</strong> Averaged human annotation saving ratio before and after fine-tuning for GRM-Gemma-2B-sftreg and Skywork-Reward-Llama-3.1-8B-v0.2 on Chatbot Arena and MT-Bench. Under all setups, we observe at least 5% increase in the saving ratio.
        </p>
      </div>
    </div>
    
  </div>
</section>
<!--/ finetune -->

<!-- Algorithm -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width has-text-justified">
        <h2 class="title is-3 has-text-centered">Algorithm</h2>
        <div class="content has-text-justified">
          <p>
            Our method is based on control variates, a classical variance reduction method. Given human preference score \( z \) and synthetic preference score \( \hat z \) on one response pair, Control Variates Evaluation outputs a variance reduced estimate
            \[
            z^{\mathsf{cv}; \alpha} = z - \alpha (\hat z - \mu_{\hat z}),
            \]
            Here $\mu_{\hat z}$ is the synthetic win rate, computed by the mean of synthetic preference score overall samples in the evaluation dataset. $\alpha$ controls the variance of evaluation, which has optimal value
            \[
            \alpha^* = \frac{\mathrm{Cov}[z, \hat z]}{\mathrm{Var}[\hat z]}.
            \]
            In practice, $\alpha^*$ is estimated on response pairs with both human and synthetic evaluations. The output win rate is the mean of $z^{\mathsf{cv}; \alpha}$ over all human-annotated response pairs.
          </p>
        </div>
        <div class="content has-text-justified">
          <p>
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!--/ Algorithm -->




<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{zhou2025accelerating,
      author    = {Zhou, Zhaoyi and Song, Yuda and Zanette, Andrea},
      title     = {Accelerating Unbiased LLM Evaluation via Synthetic Feedback}, 
      booktitle = {ArXiv Preprint},
      year      = {2025},
    }</code></pre>

  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <!-- <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a> -->
        <div class="content">
          <p>
            Website template from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>.
          </p>
        </div>
    </div>
  </div>
</footer>

</body>
</html>
