---
permalink: /
title: "About"
excerpt: "About"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hello! I am an incoming Ph.D. student at Carnegie Mellon University (CMU) in [Electrical and Computer Engineering (ECE)](https://www.ece.cmu.edu/), starting from Fall 2024. Prior to that, I completed my undergraduate program from Yao Class at [IIIS](https://iiis.tsinghua.edu.cn/en/), [Tsinghua University](https://www.tsinghua.edu.cn/en/).

My research passion lies in designing scalable and efficient algorithms for practical machine learning systems. For this aim, I am interested in a broad spectrum of topics, including but not limited to large language models, distributed machine learning and reinforcement learning. During my undergraduate studies, I focused on reinforcement learning, developing algorithms that integrate rigorous theoretical foundations with real-world practicality.

I am open to collaborations. If you have any ideas which we both might be interested in, please feel free to reach out!

# Selected Research
<!-- - June 2023 - now: Optimization, supervised by Prof. [Jingzhao Zhang](https://sites.google.com/view/jingzhao/home). We hope to extend parameter-free optimization in stochastic gradient setting. -->
## Model-based return-conditioned supervised learning
Research intern at UW (Feb. 2023 - Aug. 2023).

Supervisor: [Simon S. Du](https://simonshaoleidu.com/). 

<!-- ![mbrcsl](../images/mbrcsl.png) -->
 <img src="../images/mbrcsl.png" style="zoom:33%;" />

We proposed model-based return-conditioned supervised learning (**MBRCSL**), a novel offline RL framework that is able to do trajectory stitching while retaining the strength of return-conditioned supervised learning (RCSL) to avoid Bellman completeness requirements. [[website]](mbrcsl_website/)

<!-- - Feb 2023 - now: Offline RL, supervised by Prof. [Simon Shaolei Du](https://simonshaoleidu.com/) at University of Washington. We aim to discover advantages of decision transformer (DT) over classical offline RL algorithms from theoretical perspective, and improve DT to cope with issue of trajectory stitching.  -->

## Networked Markov Potential Games 
Remote research intern at Caltech (Feb. 2022 - Feb. 2023).

Supervisor: [Adam Wierman](https://adamwierman.com/).

<img src="../images/NMPG.png" style="zoom:33%;" />

We proposed networked Markov potential games (NMPG) as a more practical relaxation of Markov potential games (MPG), and designed a localized actor-critic algorithm with provable finite-sample bound. [[arXiv]](https://arxiv.org/abs/2303.04865)

<!-- - Feb 2022 - Feb 2023: Networked MARL, supervised (remotely) by Prof. [Adam Wierman](https://adamwierman.com/) at Caltech. We introduced a class of networked Markov potential games, designed a localized actor-critic algorithm and derived the first finite-sample bound for multi-agent competitive games that is independent of the number of agents. See our paper on [arXiv](https://arxiv.org/abs/2303.04865). -->

<!-- # Skills
- Proficient in mathematical knowledge for ML research: calculus, linear algebra, abstract algebra, probability theory and optimization. 
- Experienced in common programming language: C++, Python, Go, Verilog.
- Familiar with AI frameworks: Pytorch -->

# News
- Jan 2024: One [paper](https://arxiv.org/abs/2310.19308) accepted by ICLR 2024!
- Nov 2023: One [paper](https://arxiv.org/abs/2310.19308) accepted by NeurIPS 2023 [FMDM](https://sites.google.com/view/fmdm-neurips23/home) workshop (**oral**)! Thanks for efforts from all collaborators!
- Aug 2023: Participate in UAI 2023.
- May 2023: One [paper](https://arxiv.org/abs/2303.04865) accepted by UAI 2023! Thanks for generous support from Dr. [Zaiwei Chen](https://www.zaiweichen.com/home), [Yiheng Lin](https://yihenglin97.github.io/) and Prof. [Adam Wierman](https://adamwierman.com/).
- Feb 2023: Begin my spring visit at UW. Look forward to cooperation with Prof. [Simon Shaolei Du](https://simonshaoleidu.com/).